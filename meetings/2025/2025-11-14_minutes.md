# SING 2025-11-14

## Introduction

Simone: I’m Simone, and I’m the Security Lead at W3C. Please send me that information, and I’ll try to take care of security on the web. You can go—yeah, from that direction.

Joe: I’m . I’m the use case editor for the VC and DID work, and I’m also an editor for the Web Threat Modeling Guide—well, the threat modeling guide, and also the Threat Model for the Web. We’ll talk about that a little bit later. And I think that’s all.

Kristenson: I’m here from the security and credentials community, mostly observing. I’m Kristenson from Apple.

Kimmy: Yeah, I’m Kimmy, from security—also observing, mostly. Thank you.

Thomas: My name is Thomas. I’m an invited expert in the RDF group. Thank you.

Tatia: My name is Tatia, from Japan. I started my career here… I did some writing, and after that I engaged in security work. Thanks.

Zahra: I’m looking at DC API threat modeling.

Amir: I’m a researcher from Fondazione Bruno Kessler, and both of us are from the Cybersecurity Center at Fondazione Bruno Kessler. We’ve been working in the field of digital identity for quite a long time, and we do a lot of threat modeling and security and privacy by design as our main research lines. I’m part of the Threat Modeling Community Group and the Security Interest Group.

Anssi: I’m the Web Machine Learning Working Group Chair. We work on the Neural Network API, known as WebNN API—it’s on the agenda. The Security Interest Group has been helping us harden the API for security. We’ll talk about that, and I will invite my co-chair, Riley, from Google, when we get to that session.

Simone: Okay. Thank you for the introductions and for being here. This is our first meeting, because the group was formed last year. Sadly, a lot of our members are not here, and it’s also not a good time zone for Japan. So thank you also to all the guests.

## Next Meeting

Simone: The next meeting will be on 25 November, if you like—it’s compatible with the US and the EU. If you would like to join and need a specific time zone, just ask us—we have to be flexible. We have bi-weekly meetings for synchronisation of some topics, and the second one is on 9 December.

## Deliverables

Simone: We have some deliverables we are working on, and there was a lot of discussion about the group and these deliverables. One deliverable is the “Cryptographic Usage in Web Standards” document. Veronica—who is not here because it’s night for her—is taking care of the various comments.
The need for the document is, in particular, for reviewers and spec developers: to have an introductory document on cryptography. There was an interesting discussion during the breakout, and the question is: we validated that there is a need for the document, but we are still discussing the correct form. Some folks proposed splitting it into something more introductory and something more technical.
If you’d like to review, please be really active. I also noticed that at the latest IETF in Montreal there was CFRG discussion about doing a similar document. Maybe we are going to have a joint effort. We are evaluating the future of the document. Anyone interested can find it on the repo. It’s just the first study draft—not final—meant to validate the need.
And, as we say: if you are working on a spec and you need cryptography, please don’t invent your own cryptography. This will probably be a big disclaimer in the document. It will also be useful for reviewing standards—especially for work like Verifiable Credentials, which relies a lot on cryptography—so reviewers can quickly check whether something makes sense, or have it as a point of reference.
Another work item is threat models. The Threat Modeling Community Group was formed earlier, and it’s a community group—anyone can join. The idea is to bring people from privacy, security, and also human rights, which is an important topic, and the United Nations is pushing SDOs like W3C to work on these topics. So we are doing some experiments.
AI, browsers, and the web is a complex topic. Our approach is to create small threat models connected to each other. This approach is often useful in threat modeling guides. That’s why we have one Threat Model for the Web, in particular for the problem of the web “ABI”, and another one on the agentic world.
Prompt API is in the Community Group—yes, it’s in the Community Group. It will be landing in the Web Machine Learning work. We have two groups: Working Group and Community Group.
It was nice because Tom, the editor, engaged directly on the mailing list and GitHub. There was a lot of interesting discussion on GitHub. We also have a threat model for agentic browsers. Now there’s also Perplexity, and there is also now a browser from OpenAI, so there was a long discussion—but the threat models are in the Threat Modeling Community Group, and we need to move them into this group, and maybe later they can be adopted by Working Groups working on specific specs.
We also have the Threat Model for the Web (a medium-level threat model). We discussed this in WebEng meetings, and it’s meant to help spec developers avoid losing a lot of time by having something pre-filled to quickly analyse a web API.
Another document is the Threat Modeling Guide: a guide for doing threat models and how to obtain Security Considerations sections from a threat model. We are working with Joe, and it will be the next topic.
Then we also have a large threat model for the Digital Credentials. This is important because it’s an ecosystem-level threat model, so it’s not only W3C: it has dependencies at different layers of the architecture, and it’s useful for understanding the societal impact of the technology.
We discussed this morning in the FedCM Working Group. Digital Credentials API is just a small piece—one pipe—in the broader credentials ecosystem. To understand threats, and in particular harms (the social impact), we prefer to also have higher-level analysis. We are not going to bore spec developers with ecosystem threats, but this can be a place to talk also with other SDOs, governments, and others.
For example, this work received a formal objection about these topics, and some harms include opportunity loss, economic loss, dignity loss, and autonomy loss. There was higher-level reflection on the topic.
For this, the transition request was approved for publishing the first draft note. After moratorium, we will publish.
Another document we are working on officially is security disclosure best practices. This was born in W3C around EME, and it explains how to disclose vulnerabilities related to an already standardised specification. We updated it to be compatible with different approaches and best practices in vulnerability management. We received a Chair decision to publish, and this will be processed.
The objective of the group is to make the web safer and also to be ready to receive disclosures by developers. We are experimenting with this process. We also receive vulnerabilities on standards without a group—so what do we do? If someone would like to join me in reviewing disclosures, you are welcome. It’s interesting to do with security researchers. For me, it’s also a nice experience, because often I was the one sending reports—now I’m receiving them.
Then we have ongoing reviews. As you know, we always have a long queue of reviews, and we received feedback and criticism about that. Reviewing a spec is an art: it requires understanding the spec and common vulnerabilities. We are also going to talk with Process CG to find a good way. If there are proposals or volunteers for reviewing specs, that’s why we are here.
Okay—now I’ll leave the mic to Joe.

Joe: I have a tough question. About the Threat Model for Digital Credentials: how do you see that fitting in for, say, the VC Data Model? Will they be able to at least point to that threat model?

Simone: My understanding is that this threat model is ecosystem-level and more about the general use of digital credentials, not one specific specification.

Joe: I’m not familiar with it, but my sensitivity is: threat modeling wants to get specific. If you generalise too much, you end up mixing different flows (mDL, DC API, etc.) that have different threats. That’s my gut response. But it can still be a base for working on VCDM, and it can be a source of threats you might include in the more specific models.Okay—did you want me to talk about the Threat Modeling Guide?

## Threat Modeling Guide

Joe: So, some context: we did a breakout session. The question is: how do you threat model the web at that scale? W3C has published about 500 Recommendations, and we depend on many other specifications. There are too many moving parts to do it all at once. So our approach is to build a constellation of small threat models that work together because they share a common language and a common architecture.
In the guide, we talk about our goals, the legacy of threat modeling, and different frameworks. We want working groups to have the freedom to use the analytical framework that fits their expertise. If you want to list harms, that’s fine. If you want to use STRIDE, that’s fine. The point is to capture the working group’s expertise and document why they built it the way they did.
One thing we want to anchor is a visual diagram that identifies components in the system. Without that diagram, it’s hard to understand the context and the threats. You may also develop multiple threat models for the same system with different diagrams, depending on what you are analysing.

Simone: We discussed this morning that the first thing a working group should add—maybe even during the explainer phase—is a diagram. It can save months of understanding, compared to reading 100 pages of spec. 

Joe: I’m also an advocate for identifying threats in the charter if you already know them. We also identified four types of “threats” for specifications:
- Target threats: threats the spec was designed to address.
- Implementation threats: issues implementers must consider (e.g., key management).
- External threats: real threats the spec cannot solve, but should acknowledge (e.g., over-the-shoulder attacks).
- Dependency threats: threats due to dependencies (e.g., relying on TLS).

And one more point: treat threat modeling as storytelling. Curate the most salient threats and make it readable. Concrete threats help regulators, lay people, CEOs, and others understand what the technology addresses. If it’s a wall of text, nobody reads it.
In my example, I use a DFD-style model: entities, trust boundaries, processes, data stores, data flows. I also include a dictionary to define each component. Then I use one table per threat (not one spreadsheet for everything), and I identify the analysis framework used—because frameworks define terms differently.

Zara: For one threat, you can have different scenarios, and controls change the responses. Do you consider that?

Joe: Great question. I haven’t fully solved it here, but if the variations matter, I’d list them as separate threats. Okay—we’ll come back later on an important point about an evolution we are doing in threat modeling as a process. 


## Human Web-Threat Model

Simone: The next topic is 5–10 minutes on the Human-Web Threat Model, which adds another dimension.

Simone: This was an experiment going beyond classical technical vulnerabilities, inspired by Gerd Gigerenzer and behavioural economics. The idea is to merge psychology with web threat modeling, and use “harms” as a framework—negative societal impacts—alongside threats. Thinking fast / thinking slow: we react to stimuli using different processes, and many attacks (like phishing) work by triggering fast reactions without deeper thinking.
We explored concepts like over-reliance on algorithms, distortion of reality, and reduction of autonomy. We mapped cognitive harms (attention hijacking, cognitive overload, memory and emotion manipulation, autonomy undermining, misinformation) to more manageable pairs that can then be treated in more traditional threat modeling frameworks.
We also considered response strategies: eliminate, reduce, transfer, accept. A key finding was that mapping harms to threats makes the space more manageable and actionable for web work.

Question: What’s the pathway to publish this so we can refer to it?

Simone: More or less by the end of the year. We want to publish it as a Note via the Threat Modeling Community Group, and then we can consider adoption.
To close this point: after this experiment, we tried to merge the threat modeling process with harms modeling to have a unified approach, to avoid asking working groups to do both separately. We are aiming—hopefully before Christmas—to include this in our guide.

We propose: model the system (diagram), identify threats, consider responses, and add stakeholder analysis. For some contexts, you may need to define different stakeholder categories (e.g., non-users affected by exclusion). This can also apply to AI contexts.

Joe: Even in the simple web model we focus on TLS, but in other contexts user characteristics matter: sight, guardianship, underage, etc. Those create different threats.

Discussion: should we also include goals and security properties? Maybe yes—goals of stakeholders can drive the model. We also noted terminology differences (threat, risk, harm), and we should avoid “positive risk” in this context.
We agreed we should synchronise terminology: components vs assets, and how we capture affected assets.

## WebNN

Anssi: Now, WebNN: the Web Machine Learning Working Group has multiple deliverables. We have WebNN (low-level inference acceleration), and also higher-level “built-in AI” APIs, like writing assistants, translation, proofreading, etc., and we are incubating new web features. WebNN is a low-level inference capability that accelerates neural network operations on hardware. You start with models in frameworks like PyTorch, convert/optimise for edge deployment, and then WebNN is another target option (alongside WebAssembly or WebGPU) that can hand off execution to native platform components (GPU tensor cores, NPUs, etc.). It’s an abstraction over the compute capabilities of the device.
Security-wise, the model is similar to WebGPU: you provide a program to a native component that must execute it safely; there can be complex compiler stacks, so fuzzing and validation matter. The exact risks depend on architecture and memory isolation, but overall the threat model is comparable.

Simone: For us, 99% of understanding starts with a diagram. The level of detail in the diagram changes which threats we find. We should align diagrams and then identify threats. Let threats drive what detail you need in the diagram.
We can synchronise diagrams and threat modeling approaches and then collaborate. We will invite you to future calls when we have a draft.

Anssi: Web MCP API: it’s related to agentic interaction. Without it, agents may scrape via screenshots and cloud vision models. With MCP, the website defines “tools” for agents to use, which could reduce scraping and token use. But malicious sites remain a threat: a site can still behave maliciously with or without MCP.

## DID Resolution

Will: the DID Resolution spec defines interfaces for resolve / dereference, with an HTTPS binding. Security analysis depends heavily on DID methods (did:key, did:web, ledger-based methods), proxy resolution patterns, and infrastructure choices (local vs external resolvers). We don’t want to threat model 200+ individual methods, but we can model classes of architectures and trust boundaries.
We agreed: don’t block CR; do an initial pass with diagrams and initial threats, then bring the Security Interest Group in for deeper analysis during CR. Security considerations should indicate “at risk” where appropriate.
We are also welcoming more participants—more people means more capacity to make the web safer.
